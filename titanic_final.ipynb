{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4454f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4353d249",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data.csv\") \n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "features = ['Sex','Parch','Age','Pclass', 'Embarked', 'Fare']\n",
    "\n",
    "# filling missing values with mean\n",
    "age_avg = train_df.Age.mean()\n",
    "train_df['Age'] = train_df['Age'].fillna(age_avg)\n",
    "fare_avg = train_df['Fare'].mean()\n",
    "train_df['Fare'] = train_df['Fare'].fillna(fare_avg)\n",
    "\n",
    "X = train_df[features]\n",
    "y = train_df['Survived']\n",
    "X_train, X_valid, y_train, y_val = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "\n",
    "# clean data for df used for submission\n",
    "submission_df = pd.read_csv(\"submission_data.csv\")\n",
    "passenger_id = submission_df['PassengerId'] # needs to be saved later for submission\n",
    "submission_df = submission_df[features]\n",
    "age_avgs = submission_df['Age'].mean()\n",
    "submission_df['Age'] = submission_df['Age'].fillna(age_avgs)\n",
    "fare_avgs = submission_df['Fare'].mean()\n",
    "train_df['Fare'] = submission_df['Fare'].fillna(fare_avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bfc3e4-b406-492e-8377-c339f8cbf17c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "901d3f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use one-hot encoder on categorical variables\n",
    "object_cols = ['Sex', 'Embarked']\n",
    "\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[object_cols]))\n",
    "OH_sub = pd.DataFrame(OH_encoder.transform(submission_df[object_cols]))\n",
    "\n",
    "# put indexes back\n",
    "OH_cols_train.index = X_train.index\n",
    "OH_cols_valid.index = X_valid.index\n",
    "OH_sub.index = submission_df.index\n",
    "\n",
    "# Remove categorical columns\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_valid = X_valid.drop(object_cols, axis=1)\n",
    "num_sub = submission_df.drop(object_cols, axis = 1)\n",
    "\n",
    "# Add one-hot encoded columns to numerical features\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "OH_sub = pd.concat([num_sub, OH_sub], axis=1)\n",
    "\n",
    "OH_X_train.columns = OH_X_train.columns.astype(str)\n",
    "OH_X_valid.columns = OH_X_valid.columns.astype(str)\n",
    "OH_sub.columns = OH_sub.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "830bd0ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "forest_model = RandomForestClassifier()\n",
    "forest_model.fit(OH_X_train, y_train)\n",
    "predictions = forest_model.predict(OH_X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f67e06bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8295964125560538\n"
     ]
    }
   ],
   "source": [
    "def accuracy(actual, pred):\n",
    "    return (actual == pred).mean()\n",
    "\n",
    "print(accuracy(y_val, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d409ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7982062780269058\n"
     ]
    }
   ],
   "source": [
    "log_reg_model = LogisticRegression(max_iter = 500)\n",
    "log_reg_model.fit(OH_X_train, y_train)\n",
    "preds_log = log_reg_model.predict(OH_X_valid)\n",
    "print(accuracy(y_val, preds_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79dc72a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7399103139013453\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(OH_X_train, y_train)\n",
    "preds_gnb = gnb_model.predict(OH_X_valid)\n",
    "print(accuracy(y_val, preds_gnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa84c931-3e31-45be-b099-69e1bdc8e160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the most accurate model, random forest, to the final submission predictions\n",
    "final_preds = forest_model.predict(OH_sub)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5a69ac9-f843-4437-b948-2851d6b8c70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70c93478-7f1e-4725-bd5c-2946ac3484c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.concat([passenger_id, pd.Series(final_preds)], axis=1)\n",
    "predictions.to_csv('predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0a05c3-52ee-465c-9770-601cf3a1f72f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
